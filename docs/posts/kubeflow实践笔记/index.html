<!DOCTYPE html>

















<html lang="en-us">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  
  <title>Kubeflow实践笔记 - 朱亚光的博客</title>

  
  
  <meta name="description" content="基于 Kubernetes 的云原生 AI 平台建设 提高算力资源利用  GPU 虚拟化  GPUManager 基于 GPU 驱动封装实现，用户需要对驱动的某些关键接口（如显存分配、cuda thread 创建等）进行封装劫持，在劫持过程中限制用户进程对计算资源的使用，整体方案较为轻量化、性能损耗小，自身只有 5% 的性能损耗，支持同一张卡上容器间 GPU 和显存使用隔离，保证了编码这种算力利用率不高的场景开发者可以共享 GPU，同时在同一块调试时资源不会被抢占。
训练集群算力调度  在 Kubernetes 里面使用 Job 来创建训练任务，只需要指定需要使用的GPU资源，结合消息队列，训练集群算力资源利用率可以达到满载。
资源监控  资源监控对集群编码、训练优化有关键指导作用，可以限制每个项目 GPU 总的使用量和每个用户GPU 资源分配。
kubeflow介绍 Kubeflow 是 google 开发的包含了机器学习模型开发生命周期的开源平台。 Kubeflow 由一组工具组成，这些工具解决了机器学习生命周期中的每个阶段，例如：数据探索、特征工程、特征转换、模型实验、模型训练、模型评估、模型调整、模型服务和 模型版本控制。 kubeflow 的主要属性是它被设计为在 kubernetes 之上工作，也就是说，kubeflow 利用了 kubernetes 集群提供的好处，例如容器编排和自动扩展。
Kubeflow components in the ML workflow Kubeflow user interface (UI) ![image-20220328102313469](/Users/zhuyaguang/Library/Application Support/typora-user-images/image-20220328102313469.png)
http://10.101.32.26:8080/
 Distributed training with Kubeflow pipeline https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training
Natural-Language-Processing https://github." />
  <meta name="author" content="" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://zhuyaguang.github.io/app.min.css" />

  

  
  <link rel="preload" as="image" href="https://zhuyaguang.github.io/theme.png" />

  
  <link rel="preload" as="image" href="https://zhuyaguang.github.io/twitter.svg" />
  
  <link rel="preload" as="image" href="https://zhuyaguang.github.io/github.svg" />
  
  <link rel="preload" as="image" href="https://zhuyaguang.github.io/instagram.svg" />
  

  
  <link rel="icon" href="https://zhuyaguang.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://zhuyaguang.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.96.0" />

  
  

  
  
  
  
  
  
  
  
  
  <meta property="og:title" content="Kubeflow实践笔记" />
<meta property="og:description" content="基于 Kubernetes 的云原生 AI 平台建设 提高算力资源利用  GPU 虚拟化  GPUManager 基于 GPU 驱动封装实现，用户需要对驱动的某些关键接口（如显存分配、cuda thread 创建等）进行封装劫持，在劫持过程中限制用户进程对计算资源的使用，整体方案较为轻量化、性能损耗小，自身只有 5% 的性能损耗，支持同一张卡上容器间 GPU 和显存使用隔离，保证了编码这种算力利用率不高的场景开发者可以共享 GPU，同时在同一块调试时资源不会被抢占。
训练集群算力调度  在 Kubernetes 里面使用 Job 来创建训练任务，只需要指定需要使用的GPU资源，结合消息队列，训练集群算力资源利用率可以达到满载。
资源监控  资源监控对集群编码、训练优化有关键指导作用，可以限制每个项目 GPU 总的使用量和每个用户GPU 资源分配。
kubeflow介绍 Kubeflow 是 google 开发的包含了机器学习模型开发生命周期的开源平台。 Kubeflow 由一组工具组成，这些工具解决了机器学习生命周期中的每个阶段，例如：数据探索、特征工程、特征转换、模型实验、模型训练、模型评估、模型调整、模型服务和 模型版本控制。 kubeflow 的主要属性是它被设计为在 kubernetes 之上工作，也就是说，kubeflow 利用了 kubernetes 集群提供的好处，例如容器编排和自动扩展。
Kubeflow components in the ML workflow Kubeflow user interface (UI) ![image-20220328102313469](/Users/zhuyaguang/Library/Application Support/typora-user-images/image-20220328102313469.png)
http://10.101.32.26:8080/
 Distributed training with Kubeflow pipeline https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training
Natural-Language-Processing https://github." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhuyaguang.github.io/posts/kubeflow%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-10T08:47:52+08:00" />
<meta property="article:modified_time" content="2022-04-10T08:47:52+08:00" />


  
  <meta itemprop="name" content="Kubeflow实践笔记">
<meta itemprop="description" content="基于 Kubernetes 的云原生 AI 平台建设 提高算力资源利用  GPU 虚拟化  GPUManager 基于 GPU 驱动封装实现，用户需要对驱动的某些关键接口（如显存分配、cuda thread 创建等）进行封装劫持，在劫持过程中限制用户进程对计算资源的使用，整体方案较为轻量化、性能损耗小，自身只有 5% 的性能损耗，支持同一张卡上容器间 GPU 和显存使用隔离，保证了编码这种算力利用率不高的场景开发者可以共享 GPU，同时在同一块调试时资源不会被抢占。
训练集群算力调度  在 Kubernetes 里面使用 Job 来创建训练任务，只需要指定需要使用的GPU资源，结合消息队列，训练集群算力资源利用率可以达到满载。
资源监控  资源监控对集群编码、训练优化有关键指导作用，可以限制每个项目 GPU 总的使用量和每个用户GPU 资源分配。
kubeflow介绍 Kubeflow 是 google 开发的包含了机器学习模型开发生命周期的开源平台。 Kubeflow 由一组工具组成，这些工具解决了机器学习生命周期中的每个阶段，例如：数据探索、特征工程、特征转换、模型实验、模型训练、模型评估、模型调整、模型服务和 模型版本控制。 kubeflow 的主要属性是它被设计为在 kubernetes 之上工作，也就是说，kubeflow 利用了 kubernetes 集群提供的好处，例如容器编排和自动扩展。
Kubeflow components in the ML workflow Kubeflow user interface (UI) ![image-20220328102313469](/Users/zhuyaguang/Library/Application Support/typora-user-images/image-20220328102313469.png)
http://10.101.32.26:8080/
 Distributed training with Kubeflow pipeline https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training
Natural-Language-Processing https://github."><meta itemprop="datePublished" content="2022-04-10T08:47:52+08:00" />
<meta itemprop="dateModified" content="2022-04-10T08:47:52+08:00" />
<meta itemprop="wordCount" content="237">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kubeflow实践笔记"/>
<meta name="twitter:description" content="基于 Kubernetes 的云原生 AI 平台建设 提高算力资源利用  GPU 虚拟化  GPUManager 基于 GPU 驱动封装实现，用户需要对驱动的某些关键接口（如显存分配、cuda thread 创建等）进行封装劫持，在劫持过程中限制用户进程对计算资源的使用，整体方案较为轻量化、性能损耗小，自身只有 5% 的性能损耗，支持同一张卡上容器间 GPU 和显存使用隔离，保证了编码这种算力利用率不高的场景开发者可以共享 GPU，同时在同一块调试时资源不会被抢占。
训练集群算力调度  在 Kubernetes 里面使用 Job 来创建训练任务，只需要指定需要使用的GPU资源，结合消息队列，训练集群算力资源利用率可以达到满载。
资源监控  资源监控对集群编码、训练优化有关键指导作用，可以限制每个项目 GPU 总的使用量和每个用户GPU 资源分配。
kubeflow介绍 Kubeflow 是 google 开发的包含了机器学习模型开发生命周期的开源平台。 Kubeflow 由一组工具组成，这些工具解决了机器学习生命周期中的每个阶段，例如：数据探索、特征工程、特征转换、模型实验、模型训练、模型评估、模型调整、模型服务和 模型版本控制。 kubeflow 的主要属性是它被设计为在 kubernetes 之上工作，也就是说，kubeflow 利用了 kubernetes 集群提供的好处，例如容器编排和自动扩展。
Kubeflow components in the ML workflow Kubeflow user interface (UI) ![image-20220328102313469](/Users/zhuyaguang/Library/Application Support/typora-user-images/image-20220328102313469.png)
http://10.101.32.26:8080/
 Distributed training with Kubeflow pipeline https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training
Natural-Language-Processing https://github."/>

  
  
</head>


  <body class="not-ready" data-menu="false">
    <header class="header">
  
  <p class="logo">
    <a class="site-name" href="https://zhuyaguang.github.io/">朱亚光的博客</a><a class="btn-dark"></a>
  </p>
  

  <script>
    let bodyClx = document.body.classList;
    let btnDark = document.querySelector('.btn-dark');
    let sysDark = window.matchMedia('(prefers-color-scheme: dark)');
    let darkVal = localStorage.getItem('dark');

    let setDark = (isDark) => {
      bodyClx[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark ? 'yes' : 'no');
    };

    setDark(darkVal ? darkVal === 'yes' : sysDark.matches);
    requestAnimationFrame(() => bodyClx.remove('not-ready'));

    btnDark.addEventListener('click', () => setDark(!bodyClx.contains('dark')));
    sysDark.addEventListener('change', (event) => setDark(event.matches));
  </script>

  
  

  
  <nav class="social">
    
    <a
      class="twitter"
      style="--url: url(./twitter.svg)"
      href="https://twitter.com/SurfingSnail"
      target="_blank"
    ></a>
    
    <a
      class="github"
      style="--url: url(./github.svg)"
      href="https://github.com/zhuyaguang"
      target="_blank"
    ></a>
    
    <a
      class="instagram"
      style="--url: url(./instagram.svg)"
      href="https://instagram.com/YOUR_INSTAGRAM_ID"
      target="_blank"
    ></a>
    
  </nav>
  
</header>


    <main class="main">

<article class="post-single">
  <header class="post-title">
    <p>
      
      <time>Apr 10, 2022</time>
      
      
    </p>
    <h1>Kubeflow实践笔记</h1>
  </header>
  <section class="post-content"><h1 id="基于-kubernetes-的云原生-ai-平台建设">基于 Kubernetes 的云原生 AI 平台建设</h1>
<h3 id="提高算力资源利用">提高算力资源利用</h3>
<ol>
<li>GPU 虚拟化</li>
</ol>
<p>GPUManager 基于 GPU 驱动封装实现，用户需要对驱动的某些关键接口（如显存分配、cuda thread 创建等）进行封装劫持，在劫持过程中限制用户进程对计算资源的使用，整体方案较为轻量化、性能损耗小，自身只有 5% 的性能损耗，支持同一张卡上容器间 GPU 和显存使用隔离，保证了编码这种算力利用率不高的场景开发者可以共享 GPU，同时在同一块调试时资源不会被抢占。</p>
<ol start="2">
<li>训练集群算力调度</li>
</ol>
<p>在 Kubernetes 里面使用 Job 来创建训练任务，只需要指定需要使用的GPU资源，结合消息队列，训练集群算力资源利用率可以达到满载。</p>
<ol start="3">
<li>资源监控</li>
</ol>
<p>资源监控对集群编码、训练优化有关键指导作用，可以限制每个项目 GPU 总的使用量和每个用户GPU 资源分配。</p>
<p><img src="https://miro.medium.com/max/1400/1*LhL7j9QhwgQCO4bMu-CNjw.jpeg" alt="img"></p>
<h3 id="kubeflow介绍">kubeflow介绍</h3>
<p>Kubeflow 是 google 开发的包含了机器学习模型开发生命周期的开源平台。 Kubeflow 由一组工具组成，这些工具解决了机器学习生命周期中的每个阶段，例如：数据探索、特征工程、特征转换、模型实验、模型训练、模型评估、模型调整、模型服务和 模型版本控制。 kubeflow 的主要属性是它被设计为在 kubernetes 之上工作，也就是说，kubeflow 利用了 kubernetes 集群提供的好处，例如容器编排和自动扩展。</p>
<p><img src="https://www.kubeflow.org/docs/images/kubeflow-overview-platform-diagram.svg" alt="An architectural overview of Kubeflow on Kubernetes"></p>
<h3 id="kubeflow-components-in-the-ml-workflow">Kubeflow components in the ML workflow</h3>
<p><img src="https://www.kubeflow.org/docs/images/kubeflow-overview-workflow-diagram-2.svg" alt="Where Kubeflow fits into a typical machine learning workflow"></p>
<h3 id="kubeflow-user-interface-ui">Kubeflow user interface (UI)</h3>
<p>![image-20220328102313469](/Users/zhuyaguang/Library/Application Support/typora-user-images/image-20220328102313469.png)</p>
<p>http://10.101.32.26:8080/</p>
<h3 id="heading"></h3>
<h3 id="distributed-training-with-kubeflow-pipeline">Distributed training with Kubeflow pipeline</h3>
<p><a href="https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training">https://github.com/kubeflow/examples/tree/master/FaceNet-distributed-training</a></p>
<p><img src="https://user-images.githubusercontent.com/51089749/137869771-50941659-9fc1-450f-ae2a-5628d9b80d2d.png" alt="img"></p>
<h3 id="natural-language-processing">Natural-Language-Processing</h3>
<p><a href="https://github.com/dfm871002/examples/blob/master/Natural-Language-Processing/3.%20Jupyter%20Notebook/Jupyter%20Notebook.md">https://github.com/dfm871002/examples/blob/master/Natural-Language-Processing/3.%20Jupyter%20Notebook/Jupyter%20Notebook.md</a></p>
<p><img src="https://github.com/dfm871002/examples/raw/master/Natural-Language-Processing/4.%20Image/pipeline.png" alt="pipeline"></p>
<h3 id="code">code</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env python</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># coding: utf-8</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># In[ ]:</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    BertConfig,
</span></span><span style="display:flex;"><span>    BertTokenizer,
</span></span><span style="display:flex;"><span>    BertForMaskedLM,
</span></span><span style="display:flex;"><span>    DataCollatorForWholeWordMask,
</span></span><span style="display:flex;"><span>    Trainer,
</span></span><span style="display:flex;"><span>    TrainingArguments,
</span></span><span style="display:flex;"><span>    LineByLineWithRefDataset
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tokenizers
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> argparse
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(args):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tokenizer_kwargs <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;model_max_length&#34;</span>: <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    tokenizer <span style="color:#f92672">=</span>  BertTokenizer<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#39;/home/hdu-sunhao/孙浩/二次训练_nezha/&#39;</span>, <span style="color:#f92672">**</span>tokenizer_kwargs)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    config_new <span style="color:#f92672">=</span> BertConfig<span style="color:#f92672">.</span>from_pretrained(args<span style="color:#f92672">.</span>config)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> BertForMaskedLM<span style="color:#f92672">.</span>from_pretrained(args<span style="color:#f92672">.</span>model, config<span style="color:#f92672">=</span>config_new)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>resize_token_embeddings(len(tokenizer))  
</span></span><span style="display:flex;"><span>                            
</span></span><span style="display:flex;"><span>    train_dataset <span style="color:#f92672">=</span> LineByLineWithRefDataset(tokenizer <span style="color:#f92672">=</span> tokenizer,file_path <span style="color:#f92672">=</span> args<span style="color:#f92672">.</span>file_path, ref_path <span style="color:#f92672">=</span> args<span style="color:#f92672">.</span>ref_path, block_size<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>)      
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    data_collator <span style="color:#f92672">=</span> DataCollatorForWholeWordMask(tokenizer<span style="color:#f92672">=</span>tokenizer, mlm<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, mlm_probability<span style="color:#f92672">=</span><span style="color:#ae81ff">0.15</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    pretrain_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>    num_train_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    training_args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>        output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/home/hdu-sunhao/孙浩/二次训练_nezha/model-claims/args&#39;</span>, overwrite_output_dir<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, num_train_epochs<span style="color:#f92672">=</span>num_train_epochs, 
</span></span><span style="display:flex;"><span>        learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>, weight_decay<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, warmup_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>, local_rank <span style="color:#f92672">=</span> args<span style="color:#f92672">.</span>local_rank, <span style="color:#75715e">#dataloader_pin_memory = False,</span>
</span></span><span style="display:flex;"><span>        per_device_train_batch_size<span style="color:#f92672">=</span>pretrain_batch_size, logging_strategy <span style="color:#f92672">=</span><span style="color:#e6db74">&#34;epoch&#34;</span>,save_strategy <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;epoch&#34;</span>, save_total_limit <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span>model, args<span style="color:#f92672">=</span>training_args, data_collator<span style="color:#f92672">=</span>data_collator, train_dataset<span style="color:#f92672">=</span>train_dataset)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>    trainer<span style="color:#f92672">.</span>save_model(args<span style="color:#f92672">.</span>save_dir)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    parser <span style="color:#f92672">=</span> argparse<span style="color:#f92672">.</span>ArgumentParser(description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;nezha_train&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--config&#34;</span>, type <span style="color:#f92672">=</span> str, default <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;二次训练_nezha&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--model&#34;</span>, type <span style="color:#f92672">=</span> str, default <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;二次训练_nezha&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--file_path&#34;</span>, type <span style="color:#f92672">=</span> str, default <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;二次训练_nezha&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--ref_path&#34;</span>, type <span style="color:#f92672">=</span> str, default <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;二次训练_nezha&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--save_dir&#34;</span>, type <span style="color:#f92672">=</span> str, default <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;二次训练_nezha&#34;</span>)
</span></span><span style="display:flex;"><span>    parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;--local_rank&#34;</span>, type <span style="color:#f92672">=</span> int, default <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, help <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;For distributed training: local_rank&#34;</span>)
</span></span><span style="display:flex;"><span>    args <span style="color:#f92672">=</span> parser<span style="color:#f92672">.</span>parse_args()
</span></span><span style="display:flex;"><span>    main(args)
</span></span></code></pre></div></section>

  
  

  
  
  
  <nav class="post-nav">
     
    <a class="next" href="https://zhuyaguang.github.io/posts/hugo-command/"><span>Hugo Command</span><span>→</span></a>
    
  </nav>
  

  
  
</article>

</main>

    <footer class="footer">
  <p>&copy; 2022 <a href="https://zhuyaguang.github.io/">朱亚光的博客</a></p>
  <p>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</p>
  <p>
    <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper 5.1</a>
  </p>
</footer>

  </body>
</html>
